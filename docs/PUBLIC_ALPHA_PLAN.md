# SQL Sentinel v0.1.0 Public Alpha - 4 Day Plan

**Version:** 0.1.0
**Target Date:** 2025-02-09 (4 days from now)
**Status:** Day 2 In Progress

---

## Executive Summary

Ship a **production-ready public alpha** in 4 days (Day 0 validation + 3 days execution) focused on:
- ‚úÖ PyPI package (`pip install sqlsentinel`)
- ‚úÖ Docker Hub images (`docker pull sqlsentinel/sqlsentinel`)
- ‚úÖ GitHub repository with CI/CD
- ‚úÖ Excellent documentation enabling AI-assisted workflows
- ‚úÖ Optional: Minimal MCP server for installation/setup only

**Strategic Decision**: Focus on **excellent docs** that enable Claude Code to work WITH the existing CLI, rather than building complex NL‚ÜíSQL conversion. Let analysts use their SQL skills naturally.

---

## Package Name Confirmed ‚úÖ

**PyPI Check Results:**
- Package name: `sqlsentinel`
- Status: **AVAILABLE** ‚úÖ
- Verified: 2025-02-05

---

## Day 0: Pre-Launch Validation (CRITICAL!)

**Before making anything public, validate that SQL Sentinel actually works end-to-end.**

### Why This Matters

- Catch broken features before users do
- Verify package installation works
- Ensure examples actually run
- Test real database connectivity
- Validate notifications work
- Confirm Docker image functions

### Duration: 2-3 hours

---

### Step 0.1: Package Build & Local Installation (30 mins)

**Build the package:**
```bash
cd /workspace
poetry build
```

**Expected output:**
- `dist/sqlsentinel-0.1.0.tar.gz`
- `dist/sqlsentinel-0.1.0-py3-none-any.whl`

**Test installation in fresh environment:**
```bash
# Create isolated test environment
python -m venv /tmp/test-sqlsentinel
source /tmp/test-sqlsentinel/bin/activate

# Install from wheel
pip install dist/sqlsentinel-*.whl

# Verify CLI is available
which sqlsentinel
sqlsentinel --version
sqlsentinel --help

# Test all subcommands exist
sqlsentinel validate --help
sqlsentinel run --help
sqlsentinel daemon --help
sqlsentinel history --help
sqlsentinel healthcheck --help
sqlsentinel metrics --help
sqlsentinel silence --help
sqlsentinel unsilence --help
sqlsentinel status --help

# Cleanup
deactivate
rm -rf /tmp/test-sqlsentinel
```

**Checklist:**
- [x] Package builds without errors
- [x] Wheel file created (55KB, well under 100KB)
- [x] Installs in fresh virtualenv
- [x] `sqlsentinel` command available in PATH
- [x] All 10 subcommands present and show help
- [x] No import errors
- [x] Version number correct (0.1.0)
- [x] **Fix applied:** Added `--version` flag to CLI (was missing)

---

### Step 0.2: SQLite Alert Test (30 mins)

**Create test database:**
```bash
cd /tmp
sqlite3 test_sales.db << 'EOF'
CREATE TABLE sales (
  date DATE,
  revenue DECIMAL(10,2),
  orders INT
);

INSERT INTO sales VALUES
  (date('now', '-1 day'), 12500.00, 45),
  (date('now', '-2 days'), 8500.00, 32),
  (date('now', '-3 days'), 15000.00, 58);
EOF
```

**Create alert config:**
```yaml
# /tmp/test-alerts.yaml
database:
  url: "sqlite:////tmp/test_sales.db"

alerts:
  - name: "daily_revenue_check"
    description: "Test alert for revenue threshold"
    query: |
      SELECT
        CASE WHEN revenue < 10000 THEN 'ALERT' ELSE 'OK' END as status,
        revenue as actual_value,
        10000 as threshold,
        orders as order_count
      FROM sales
      WHERE date = date('now', '-1 day')
    schedule: "*/5 * * * *"
    notify:
      - channel: email
        recipients: ["test@example.com"]
```

**Test the alert:**
```bash
# Validate configuration
sqlsentinel validate /tmp/test-alerts.yaml

# Run alert in dry-run mode (no notifications)
sqlsentinel run /tmp/test-alerts.yaml "daily_revenue_check" --dry-run

# Initialize state database
sqlsentinel init /tmp/test-alerts.yaml --state-db /tmp/test-state.db

# Run alert with state tracking
sqlsentinel run /tmp/test-alerts.yaml "daily_revenue_check" --state-db /tmp/test-state.db

# View history
sqlsentinel history --state-db /tmp/test-state.db

# Check health
sqlsentinel healthcheck /tmp/test-alerts.yaml --state-db /tmp/test-state.db

# Cleanup
rm -f /tmp/test-alerts.yaml /tmp/test_sales.db /tmp/test-state.db
```

**Checklist:**
- [x] Config validates successfully
- [x] Dry-run executes query and shows results
- [x] Alert status detected correctly (OK ‚Äî revenue 12500 > threshold 10000)
- [x] State database initializes
- [x] Alert runs with state tracking
- [x] History shows execution record
- [x] Health check passes (HEALTHY)
- [x] No crashes or errors
- [x] Silence/unsilence and status commands also verified
- **Note:** Dry-run requires state DB to be initialized first (not blocking)

---

### Step 0.3: Multi-Database Test (15 mins)

**Test PostgreSQL connection (if available):**
```bash
# Only if you have PostgreSQL running locally or via Docker
# Skip if not available - will be tested in production

docker run -d --name postgres-test \
  -e POSTGRES_PASSWORD=test \
  -e POSTGRES_DB=testdb \
  -p 5432:5432 \
  postgres:15-alpine

# Wait for startup
sleep 5

# Create test config
cat > /tmp/pg-test.yaml << 'EOF'
database:
  url: "postgresql://postgres:test@localhost:5432/testdb"

alerts:
  - name: "pg_test"
    query: "SELECT 'OK' as status, 1 as value"
    schedule: "*/5 * * * *"
    notify: []
EOF

# Test connection
sqlsentinel validate /tmp/pg-test.yaml

# Cleanup
docker stop postgres-test && docker rm postgres-test
rm /tmp/pg-test.yaml
```

**Checklist:**
- [ ] PostgreSQL connection works (if tested)
- [ ] Query executes successfully
- [ ] Config validates
- [x] Skipped ‚Äî no PostgreSQL or Docker available in dev environment

---

### Step 0.4: Notification Test (15 mins)

**Test email notification structure (without SMTP):**
```bash
# Create config with email notification
cat > /tmp/email-test.yaml << 'EOF'
database:
  url: "sqlite:///:memory:"

alerts:
  - name: "email_test"
    query: "SELECT 'ALERT' as status, 100 as actual_value, 50 as threshold"
    schedule: "*/5 * * * *"
    notify:
      - channel: email
        recipients: ["test@example.com"]
        subject: "Test Alert: {alert_name}"
EOF

# Validate (should pass even without SMTP configured)
sqlsentinel validate /tmp/email-test.yaml

# Run in dry-run (won't actually send)
sqlsentinel run /tmp/email-test.yaml "email_test" --dry-run

rm /tmp/email-test.yaml
```

**Test webhook notification:**
```bash
# Start local webhook receiver (optional)
# nc -l 8080  # Or use webhook.site

cat > /tmp/webhook-test.yaml << 'EOF'
database:
  url: "sqlite:///:memory:"

alerts:
  - name: "webhook_test"
    query: "SELECT 'ALERT' as status, 100 as actual_value"
    schedule: "*/5 * * * *"
    notify:
      - channel: webhook
        url: "https://webhook.site/your-unique-url"
EOF

# Validate
sqlsentinel validate /tmp/webhook-test.yaml

rm /tmp/webhook-test.yaml
```

**Checklist:**
- [x] Email notification config validates
- [x] Webhook notification config validates
- [x] Dry-run mode shows alert triggered (ALERT status detected correctly)
- [x] No crashes when SMTP not configured

---

### Step 0.5: Docker Image Test (30 mins)

**Build Docker image:**
```bash
cd /workspace
docker build -t sqlsentinel-test:local .
```

**Test Docker image:**
```bash
# Test version
docker run --rm sqlsentinel-test:local sqlsentinel --version

# Test help
docker run --rm sqlsentinel-test:local sqlsentinel --help

# Test with mounted config
docker run --rm \
  -v /workspace/examples/alerts.yaml:/app/alerts.yaml \
  sqlsentinel-test:local \
  sqlsentinel validate /app/alerts.yaml

# Test healthcheck
docker run --rm \
  -v /workspace/examples/alerts.yaml:/app/alerts.yaml \
  sqlsentinel-test:local \
  sqlsentinel healthcheck /app/alerts.yaml

# Test metrics
docker run --rm sqlsentinel-test:local sqlsentinel metrics

# Cleanup
docker rmi sqlsentinel-test:local
```

**Checklist:**
- [ ] Docker image builds successfully
- [ ] Image size reasonable (< 500MB ideally)
- [ ] CLI commands work inside container
- [ ] Can mount config files
- [ ] Health check works
- [ ] Metrics command works
- [ ] No errors or warnings
- **Skipped:** Docker daemon not running in dev environment. Test on Day 2.

---

### Step 0.6: Example Configs Validation (15 mins)

**Test all example configurations:**
```bash
cd /workspace

# Test main example
sqlsentinel validate examples/alerts.yaml

# Test multi-channel example
sqlsentinel validate examples/alerts-multi-channel.yaml

# Test BigQuery example (will fail on connection, but should validate syntax)
sqlsentinel validate examples/bigquery-alerts.yaml 2>&1 | grep -i "validation" || echo "Syntax validation passed"
```

**Check example database:**
```bash
# Verify sample data exists
ls -lh examples/sample_data.db
sqlite3 examples/sample_data.db "SELECT COUNT(*) FROM orders;"
```

**Checklist:**
- [x] `alerts.yaml` validates successfully (3 alerts)
- [ ] `alerts-multi-channel.yaml` fails ‚Äî `${SLACK_WEBHOOK_URL}` env var placeholders not interpolated
- [ ] `bigquery-alerts.yaml` fails ‚Äî same env var placeholder issue
- [x] Sample database exists with data (orders: 8, api_logs: 10, data_pipeline: 3)
- [x] Main example up-to-date with current schema
- **Known issue:** Validator does not support `${VAR}` env var interpolation in URLs. Deferred.

---

### Step 0.7: Documentation Spot Check (15 mins)

**Verify critical docs exist and are accurate:**
```bash
cd /workspace

# Check README has essential sections
grep -q "Installation" README.md && echo "‚úì Installation section"
grep -q "Quick Start" README.md && echo "‚úì Quick Start section"
grep -q "AI-First" README.md && echo "‚úì AI-First section"

# Check examples are referenced
grep -q "examples/" README.md && echo "‚úì Examples referenced"

# Check essential docs exist
test -f docs/deployment/docker-guide.md && echo "‚úì Docker guide exists"
test -f docs/api/health-checks.md && echo "‚úì Health API docs exist"
test -f docs/api/metrics.md && echo "‚úì Metrics API docs exist"

# Check LICENSE exists
test -f LICENSE && echo "‚úì License exists"
```

**Checklist:**
- [x] README has installation instructions (line 317)
- [x] README has quick start ("5 minutes", line 333)
- [ ] README does NOT mention AI-first approach ‚Äî planned for Day 3
- [ ] Examples directory not referenced in README ‚Äî planned for Day 3
- [x] Essential documentation exists (Docker guide, Health API, Metrics API)
- [x] LICENSE file present (MIT)

---

### Step 0.8: Repository Cleanup Audit (30 mins)

**CRITICAL: Review all repository contents before going public!**

**Systematic file review:**

```bash
cd /workspace

# Generate file inventory
echo "=== ROOT LEVEL FILES ==="
ls -la *.md *.sh *.txt 2>/dev/null

echo -e "\n=== DOCS DIRECTORY ==="
find docs/ -type f -name "*.md" | sort

echo -e "\n=== SCRIPTS DIRECTORY ==="
ls -la scripts/

echo -e "\n=== CONFIG FILES ==="
ls -la *.yaml *.yml *.toml *.json 2>/dev/null | grep -v poetry.lock

echo -e "\n=== HIDDEN FILES ==="
ls -la .* 2>/dev/null | grep -v "^\."
```

#### Files to Review/Action

**Root Level Markdown Files:**

1. **API_SPECIFICATION.md**
   - [ ] Review: Is this current or deprecated?
   - [ ] Action: Move to `docs/archive/specs/` if deprecated, or to `docs/api/` if current
   - [ ] Decision: _[Archive/Keep/Move]_

2. **BIGQUERY_SETUP.md**
   - [ ] Review: Covered by docs/guides/bigquery-setup.md?
   - [ ] Action: Archive if duplicate, or merge into main docs
   - [ ] Decision: _[Archive/Merge/Keep]_

3. **SECURITY_PERFORMANCE_VALIDATION.md**
   - [ ] Review: Is this from early development?
   - [ ] Action: Archive if historical, or move to docs/testing/
   - [ ] Decision: _[Archive/Move/Delete]_

4. **TECHNICAL_SPEC.md**
   - [ ] Review: Current or superseded by README?
   - [ ] Action: Archive if historical, or move to docs/architecture/
   - [ ] Decision: _[Archive/Move/Keep]_

5. **SPRINT.md**
   - [ ] Review: Internal project tracking
   - [ ] Action: Keep (shows development progress) or move to docs/project/
   - [ ] Decision: _[Keep/Move]_

6. **CLAUDE.md**
   - [ ] Review: Internal instructions for Claude Code
   - [ ] Action: Keep (useful for AI-assisted development)
   - [ ] Decision: _[Keep]_ ‚úÖ

7. **README.md**
   - [ ] Review: Public-facing documentation
   - [ ] Action: Keep
   - [ ] Decision: _[Keep]_ ‚úÖ

**Scripts:**

8. **test_bigquery.sh** (root level)
   - [ ] Review: Temporary test script?
   - [ ] Action: Delete if temporary, or move to scripts/
   - [ ] Decision: _[Delete/Move]_

9. **scripts/** directory
   - [ ] docker-build.sh - Keep ‚úÖ
   - [ ] docker-test.sh - Keep ‚úÖ
   - [ ] validate-health.sh - Keep ‚úÖ
   - [ ] Any other scripts? Review and decide

**Docs Directory:**

10. **docs/archive/deprecated-plans/**
    - [ ] Review: Properly archived with README?
    - [ ] Action: Verify README.md explains why archived
    - [ ] Decision: _[Keep as-is]_ ‚úÖ

11. **docs/sprints/**
    - [ ] Review: Historical sprint completion reports
    - [ ] Action: Keep (shows project evolution) or move to archive
    - [ ] Decision: _[Keep/Archive]_

12. **docs/guides/, docs/api/, docs/deployment/**
    - [ ] Review: All current and accurate?
    - [ ] Action: Verify no WIP or draft documents
    - [ ] Decision: _[Review each]_

**Sensitive Information Check:**

```bash
# Check for potential secrets or credentials
cd /workspace

# Check for common secret patterns
echo "Checking for potential secrets..."
grep -r -i "password\|secret\|api[_-]key\|token" \
  --include="*.md" --include="*.yaml" --include="*.sh" \
  --exclude-dir=".git" --exclude-dir="node_modules" \
  . 2>/dev/null | grep -v "placeholder\|example\|CHANGEME\|your-" || echo "No secrets found"

# Check for private email addresses (not example.com)
grep -r -E "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}" \
  --include="*.md" --include="*.yaml" \
  --exclude-dir=".git" \
  . 2>/dev/null | grep -v "example.com\|test@\|noreply@" || echo "No private emails"

# Check for absolute paths that might be machine-specific
grep -r "/Users/\|/home/[^e]" \
  --include="*.md" --include="*.yaml" --include="*.sh" \
  --exclude-dir=".git" \
  . 2>/dev/null | head -5 || echo "No absolute paths"
```

**Temporary Files Check:**

```bash
# Check for common temporary file patterns
find /workspace -type f \( \
  -name "*.tmp" -o \
  -name "*.bak" -o \
  -name "*.swp" -o \
  -name "*~" -o \
  -name ".DS_Store" -o \
  -name "Thumbs.db" \
\) 2>/dev/null
```

**Git Ignored Files Review:**

```bash
# Check what's being ignored
cat .gitignore

# Verify no important files are ignored
git status --ignored
```

#### Cleanup Actions

**Create archive structure if needed:**
```bash
mkdir -p docs/archive/specs
mkdir -p docs/archive/early-docs
mkdir -p docs/project
```

**Move deprecated files:**
```bash
# Example moves (adjust based on review):
# git mv API_SPECIFICATION.md docs/archive/specs/
# git mv SECURITY_PERFORMANCE_VALIDATION.md docs/archive/early-docs/
# git mv TECHNICAL_SPEC.md docs/archive/specs/
# git mv SPRINT.md docs/project/
```

**Delete temporary files:**
```bash
# Example deletions:
# rm test_bigquery.sh
# find . -name "*.tmp" -delete
```

**Create archive README if moving files:**
```bash
cat > docs/archive/early-docs/README.md << 'EOF'
# Early Development Documentation

This directory contains documentation from early development phases,
preserved for historical reference.

These documents are **not current** but show the evolution of the project.

## Contents

- SECURITY_PERFORMANCE_VALIDATION.md - Early security/performance notes (superseded by security scans)
- [Add others as moved]

**Current Documentation:** See /docs/ directory
EOF
```

#### Final Checklist

**Repository cleanliness:**
- [x] No deprecated docs in root directory
- [ ] All archived files have explanatory READMEs
- [x] No temporary/test scripts in root
- [x] No sensitive information (credentials, private emails, API keys)
- [x] No machine-specific absolute paths
- [x] No .DS_Store, *.tmp, *.bak files
- [x] .gitignore updated with new patterns
- [x] Sprint docs removed from git tracking
- [x] Spec docs moved to docs/archive/specs/

**Public readiness:**
- [x] Root directory clean and professional
- [x] Only public-facing docs in root (README, CLAUDE.md, LICENSE)
- [x] All internal docs in docs/ or docs/project/
- [x] Archive structure clear and documented
- [x] Nothing embarrassing or confusing for external viewers

**Documentation organization:**
```
/workspace/
‚îú‚îÄ‚îÄ README.md                    ‚úÖ Public-facing
‚îú‚îÄ‚îÄ LICENSE                      ‚úÖ Public-facing
‚îú‚îÄ‚îÄ CLAUDE.md                    ‚úÖ AI development (keep)
‚îú‚îÄ‚îÄ pyproject.toml              ‚úÖ Package config
‚îú‚îÄ‚îÄ Dockerfile                  ‚úÖ Deployment
‚îú‚îÄ‚îÄ docker-compose*.yaml        ‚úÖ Deployment
‚îÇ
‚îú‚îÄ‚îÄ src/sqlsentinel/            ‚úÖ Source code
‚îú‚îÄ‚îÄ tests/                      ‚úÖ Test suite
‚îú‚îÄ‚îÄ examples/                   ‚úÖ User examples
‚îú‚îÄ‚îÄ scripts/                    ‚úÖ Operational scripts
‚îÇ
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ PUBLIC_ALPHA_PLAN.md    ‚úÖ Current plan
    ‚îú‚îÄ‚îÄ guides/                 ‚úÖ User guides
    ‚îú‚îÄ‚îÄ api/                    ‚úÖ API reference
    ‚îú‚îÄ‚îÄ deployment/             ‚úÖ Deployment docs
    ‚îú‚îÄ‚îÄ operations/             ‚úÖ Ops docs
    ‚îú‚îÄ‚îÄ project/                ‚úÖ Project tracking (SPRINT.md)
    ‚îî‚îÄ‚îÄ archive/
        ‚îú‚îÄ‚îÄ deprecated-plans/   ‚úÖ Old roadmaps
        ‚îú‚îÄ‚îÄ specs/              ‚úÖ Old specifications
        ‚îî‚îÄ‚îÄ early-docs/         ‚úÖ Historical docs
```

---

## Day 0 Summary & Sign-Off

### Issues Found

1. **Issue:** CLI missing `--version` flag
   - **Severity:** Medium
   - **Fix:** Added `--version` argument using `__version__` from `__init__.py`
   - **Status:** Fixed

2. **Issue:** Personal email `sqlsentinel@kylegehring.com` in example configs and docs
   - **Severity:** High (privacy for public release)
   - **Fix:** Replaced all instances with `alerts@example.com` across 9 files
   - **Status:** Fixed

3. **Issue:** Personal SMTP host `mail.kylegehring.com` in `.env.template`
   - **Severity:** Medium
   - **Fix:** Replaced with `smtp.example.com`, port 26 ‚Üí 587
   - **Status:** Fixed

4. **Issue:** Deprecated files cluttering root directory (5 markdown files, 3 temp scripts, security reports)
   - **Severity:** Medium (unprofessional for public release)
   - **Fix:** Archived specs/docs, deleted temp files, removed sprint docs from git, updated .gitignore
   - **Status:** Fixed

5. **Issue:** `${SLACK_WEBHOOK_URL}` env var placeholders fail Pydantic URL validation
   - **Severity:** Low (affects example configs only, not runtime)
   - **Fix:** None ‚Äî validator does not support env var interpolation
   - **Status:** Deferred

6. **Issue:** Docker and PostgreSQL tests could not run (no daemon/service in dev env)
   - **Severity:** Low (will be tested on Day 2)
   - **Status:** Deferred to Day 2

### Pre-Launch Checklist

**All items must be checked before proceeding to Day 1:**

- [x] Package builds and installs correctly
- [x] CLI commands all work
- [x] SQLite alert test passes end-to-end
- [x] Examples validate successfully (main config; multi-channel deferred)
- [ ] Docker image builds and runs (deferred ‚Äî no daemon in dev env)
- [x] Documentation is accurate
- [x] **Repository cleanup complete** (no deprecated files in root)
- [x] **No sensitive information** (credentials, private emails, API keys)
- [x] **No temporary files** (.tmp, .bak, .DS_Store)
- [x] No critical bugs found
- [x] All issues documented and resolved/deferred

### Decision Point

**STOP** - Do not proceed to Day 1 until all critical issues are resolved.

**Result:** No critical issues. All findings fixed or deferred with justification.

**Decision:** ‚úÖ Proceed to Day 1 - Repository & CI/CD Setup

---

## Day 1: Repository & CI/CD Setup

### Morning (4 hours)

#### 1.1 Create GitHub Repository
- [x] Create repository: `github.com/kyle-gehring/sql-sentinel` (**exists**)
- [ ] Set visibility to **Public** ‚ö†Ô∏è *manual action required*
- [ ] Add description: "SQL-first alerting system for data analysts" ‚ö†Ô∏è *manual action required*
- [ ] Add topics: `sql`, `alerting`, `monitoring`, `data-quality`, `python`, `ai-first` ‚ö†Ô∏è *manual action required*
- [x] Initialize with existing code (push from local)

#### 1.2 Essential Documentation Files
- [x] **CONTRIBUTING.md**
  - How to set up development environment
  - How to run tests
  - Code style guidelines
  - PR process
  - Code of Conduct (Contributor Covenant)

- [x] **CHANGELOG.md**
  - v0.1.0 initial release entry
  - Format: Keep a Changelog standard

- [x] **.github/ISSUE_TEMPLATE/**
  - `bug_report.md`
  - `feature_request.md`

- [x] **.github/PULL_REQUEST_TEMPLATE.md**
  - Checklist for PRs
  - Testing requirements
  - Documentation updates

#### 1.3 Update Repository URLs
- [x] Update `pyproject.toml`:
  - `homepage = "https://github.com/kyle-gehring/sql-sentinel"` (already set)
  - `repository = "https://github.com/kyle-gehring/sql-sentinel"` (already set)
  - `documentation = "https://github.com/kyle-gehring/sql-sentinel/tree/main/docs"` (added)

### Afternoon (4 hours)

#### 1.4 GitHub Actions CI/CD Pipeline

Create `.github/workflows/ci.yml`:

```yaml
name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.11', '3.12']

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install Poetry
      run: |
        curl -sSL https://install.python-poetry.org | python3 -
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    - name: Install dependencies
      run: poetry install

    - name: Run tests with coverage
      run: poetry run pytest --cov=src --cov-report=xml --cov-report=term

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        fail_ci_if_error: false

  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install Poetry
      run: |
        curl -sSL https://install.python-poetry.org | python3 -
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    - name: Install dependencies
      run: poetry install

    - name: Run Black
      run: poetry run black --check src/ tests/

    - name: Run Ruff
      run: poetry run ruff check src/ tests/

    - name: Run mypy
      run: poetry run mypy src/

  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install Poetry
      run: |
        curl -sSL https://install.python-poetry.org | python3 -
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    - name: Install dependencies
      run: poetry install

    - name: Run pip-audit
      run: poetry run pip-audit --skip-editable
      continue-on-error: true

    - name: Run Bandit
      run: poetry run bandit -r src/ -ll
      continue-on-error: true
```

#### 1.5 Pre-commit Configuration

Create `.pre-commit-config.yaml`:

```yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.12.1
    hooks:
      - id: black
        language_version: python3.11

  - repo: https://github.com/charliermarsh/ruff-pre-commit
    rev: v0.1.9
    hooks:
      - id: ruff
        args: [--fix]

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: check-merge-conflict
```

### Day 1 Deliverables Checklist

- [ ] GitHub repository set to public ‚ö†Ô∏è *manual action required*
- [x] CONTRIBUTING.md complete
- [x] CHANGELOG.md initialized
- [x] GitHub Actions CI/CD workflow created (`.github/workflows/ci.yml`)
- [x] Pre-commit hooks configured (already existed)
- [x] Issue/PR templates created
- [x] All URLs updated in pyproject.toml
- [x] All changes committed and pushed
- [ ] CI pipeline passes (tests, lint, security) ‚Äî verify after merge to main ‚ö†Ô∏è *manual action required*

---

## Day 2: PyPI & Docker Publishing

### Morning (4 hours)

#### 2.1 Package Testing (Local)

**Critical**: Test package locally BEFORE publishing to PyPI

```bash
# Step 1: Build the package
cd /workspace
poetry build

# Step 2: Install in a fresh virtualenv
python -m venv /tmp/test-sqlsentinel
source /tmp/test-sqlsentinel/bin/activate
pip install dist/sqlsentinel-*.whl

# Step 3: Verify installation
sqlsentinel --version
sqlsentinel --help

# Step 4: Test with example
cp examples/alerts.yaml /tmp/test-alerts.yaml
sqlsentinel validate /tmp/test-alerts.yaml

# Step 5: Cleanup
deactivate
rm -rf /tmp/test-sqlsentinel
```

**Checklist:**
- [x] Package builds without errors (56KB wheel, 47KB sdist)
- [x] Package installs in fresh venv
- [x] CLI command available (`sqlsentinel`)
- [x] All 10 subcommands work (`validate`, `run`, etc.)
- [x] Example configs validate successfully
- [x] No import errors or missing dependencies

#### 2.2 PyPI Publishing

**Prerequisites:** ‚ö†Ô∏è *all manual actions*
- [ ] Create PyPI account at https://pypi.org/account/register/
- [ ] Generate API token at https://pypi.org/manage/account/token/
- [ ] Add token to GitHub Secrets: `PYPI_TOKEN`

**Test on TestPyPI first:**

```bash
# Step 1: Publish to TestPyPI
poetry config repositories.testpypi https://test.pypi.org/legacy/
poetry config pypi-token.testpypi <YOUR_TESTPYPI_TOKEN>
poetry publish --repository testpypi

# Step 2: Test installation from TestPyPI
pip install --index-url https://test.pypi.org/simple/ sqlsentinel

# Step 3: Verify it works
sqlsentinel --version
```

**Publish to PyPI (production):**

```bash
# Step 1: Configure PyPI token
poetry config pypi-token.pypi <YOUR_PYPI_TOKEN>

# Step 2: Publish
poetry build
poetry publish

# Step 3: Verify
pip install sqlsentinel
sqlsentinel --version
```

**Checklist:** ‚ö†Ô∏è *all manual actions*
- [ ] PyPI account created
- [ ] API token generated
- [ ] Published to TestPyPI successfully
- [ ] Tested installation from TestPyPI
- [ ] Published to PyPI successfully
- [ ] Verified `pip install sqlsentinel` works
- [ ] Package page looks good on pypi.org/project/sqlsentinel

### Afternoon (4 hours)

#### 2.3 Docker Hub Publishing

**Prerequisites:** ‚ö†Ô∏è *all manual actions*
- [ ] Create Docker Hub account at https://hub.docker.com/
- [ ] Create repository: `sqlsentinel/sqlsentinel`
- [ ] Generate access token
- [ ] Add secrets to GitHub: `DOCKERHUB_USERNAME` and `DOCKERHUB_TOKEN`

**Create `.github/workflows/docker-publish.yml`:**

```yaml
name: Docker

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: sqlsentinel/sqlsentinel
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          platforms: linux/amd64,linux/arm64
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
```

**Manual Docker build and test:**

```bash
# Step 1: Build locally
docker build -t sqlsentinel/sqlsentinel:test .

# Step 2: Test the image
docker run --rm sqlsentinel/sqlsentinel:test sqlsentinel --version
docker run --rm sqlsentinel/sqlsentinel:test sqlsentinel --help

# Step 3: Test with example config
docker run --rm \
  -v $(pwd)/examples/alerts.yaml:/app/alerts.yaml \
  sqlsentinel/sqlsentinel:test \
  sqlsentinel validate /app/alerts.yaml

# Step 4: Tag and push
docker tag sqlsentinel/sqlsentinel:test sqlsentinel/sqlsentinel:latest
docker tag sqlsentinel/sqlsentinel:test sqlsentinel/sqlsentinel:0.1.0
docker push sqlsentinel/sqlsentinel:latest
docker push sqlsentinel/sqlsentinel:0.1.0
```

**Checklist:**
- [ ] Docker Hub account created
- [ ] Repository created on Docker Hub
- [x] GitHub Actions workflow for Docker created (`.github/workflows/docker-publish.yml`)
- [ ] Multi-platform images built (amd64, arm64) ‚Äî pending push + Docker Hub secrets
- [ ] Images pushed to Docker Hub
- [ ] `docker pull sqlsentinel/sqlsentinel` works
- [ ] Docker image tested with example config
- [ ] README updated with Docker instructions

### Day 2 Deliverables Checklist

- [x] Package tested locally (builds, installs, all commands work)
- [x] GitHub Actions PyPI publish workflow created (`.github/workflows/publish.yml`)
- [x] GitHub Actions Docker publish workflow created (`.github/workflows/docker-publish.yml`)
- [ ] Package published to PyPI ‚Äî requires PyPI account + `PYPI_TOKEN` secret
- [ ] `pip install sqlsentinel` works globally
- [ ] Docker images on Docker Hub ‚Äî requires Docker Hub account + secrets
- [ ] `docker pull sqlsentinel/sqlsentinel` works
- [ ] Both installation methods tested on clean system
- [ ] README updated with installation instructions

---

## Day 3: Documentation & Launch

### Morning (4 hours)

#### 3.1 Enhanced README

Update README.md with:

**New Sections:**
- [ ] **Badges** (CI status, PyPI version, Docker pulls, coverage, license)
- [ ] **Quick Demo** (animated GIF showing CLI workflow)
- [ ] **Installation** (both pip and Docker, tested)
- [ ] **5-Minute Quickstart** (simplified, works out-of-the-box)
- [ ] **AI-First Positioning** (new section on Claude Code usage)

**Example AI-First Section:**

```markdown
## AI-First Design

SQL Sentinel is designed to work naturally with AI coding assistants like Claude Code.

### Creating Alerts with Claude Code

Instead of writing YAML by hand, just describe what you want:

**You:** "I need an alert that checks if yesterday's revenue is below $10,000. Send me an email at john@company.com every morning at 9 AM."

**Claude Code will:**
1. Generate the SQL query for your database
2. Create the YAML configuration
3. Set up the schedule
4. Test the database connection
5. Validate the alert

### Example Conversation

> **You:** "Create a data quality alert for missing email addresses in the customers table"
>
> **Claude:** "I'll create an alert that checks for NULL emails. What threshold percentage should trigger the alert?"
>
> **You:** "Alert if more than 5% are missing"
>
> **Claude:** [Generates complete YAML config with SQL query]

### Common AI Tasks

- "Show me all my configured alerts"
- "Test the daily_revenue alert without sending notifications"
- "Silence the inventory_low alert for 2 hours"
- "What was the last execution result for my data quality alerts?"
- "Create an alert for [business metric]"

All of these work naturally with Claude Code - no MCP server required!
```

#### 3.2 Demo GIF Creation

**Tool:** Use `asciinema` + `agg` for terminal recording

```bash
# Install tools
pip install asciinema
cargo install --git https://github.com/asciinema/agg

# Record demo
asciinema rec demo.cast

# Convert to GIF
agg demo.cast demo.gif --speed 1.5 --theme monokai

# Or use https://terminalizer.com/
```

**Demo Script (30-60 seconds):**
1. Show: `pip install sqlsentinel` (or skip, assume installed)
2. Show: Create simple `alerts.yaml` file
3. Run: `sqlsentinel validate alerts.yaml` ‚úÖ
4. Run: `sqlsentinel run alerts.yaml "Daily Revenue" --dry-run`
5. Show: Alert triggered with notification preview
6. Run: `sqlsentinel daemon alerts.yaml` (show it starting)

**Checklist:**
- [ ] Terminal recording created
- [ ] GIF exported (< 5MB)
- [ ] GIF added to README
- [ ] Demo is clear and compelling

#### 3.3 AI-Optimized Documentation

Create `docs/ai-workflows.md`:

**Content:**
- How Claude Code can help with SQL Sentinel
- Common prompt patterns
- Example conversations
- Troubleshooting with AI
- Best practices for AI-assisted alert management

**Key Sections:**
- Getting Started with Claude Code
- Creating Alerts via Conversation
- Managing Existing Alerts
- Debugging and Troubleshooting
- Advanced Patterns

### Afternoon (4 hours)

#### 3.4 Additional Documentation

**Create/Enhance:**

- [ ] **FAQ.md** - Common questions
  - Why SQL Sentinel vs [alternative]?
  - What databases are supported?
  - How do I configure notifications?
  - How does state management work?
  - Is there a Web UI?

- [ ] **ARCHITECTURE.md** - System design
  - Component diagram
  - Data flow
  - State management
  - Deployment models

- [ ] **SECURITY.md** - Security considerations
  - Credential management
  - SQL injection prevention
  - Network security
  - Audit logging

- [ ] **examples/README.md** - Example walkthrough
  - Explain each example
  - How to customize
  - Common patterns

#### 3.5 Create GitHub Release

**Prepare v0.1.0 Release:**

```bash
# Create git tag
git tag -a v0.1.0 -m "Initial public alpha release"
git push origin v0.1.0
```

**Release Notes Template:**

```markdown
# SQL Sentinel v0.1.0 - Public Alpha üéâ

First public release of SQL Sentinel, an AI-first SQL alerting system for data analysts.

## What's New

- ‚úÖ Complete SQL-first alerting engine
- ‚úÖ Multi-database support (PostgreSQL, MySQL, SQLite, BigQuery, etc.)
- ‚úÖ Email, Slack, and Webhook notifications
- ‚úÖ Cron-based scheduling with daemon mode
- ‚úÖ State management and alert deduplication
- ‚úÖ Health checks and Prometheus metrics
- ‚úÖ 92.9% test coverage (530 passing tests)
- ‚úÖ Docker deployment ready
- ‚úÖ AI-friendly CLI design

## Installation

### PyPI
```bash
pip install sqlsentinel
```

### Docker
```bash
docker pull sqlsentinel/sqlsentinel:latest
```

## Quick Start

[Link to README quickstart section]

## AI-First Design

SQL Sentinel works naturally with AI coding assistants like Claude Code. [Learn more](docs/ai-workflows.md)

## Known Limitations

- Web UI not included (use CLI or AI assistants)
- Advanced multi-cloud features coming in v0.2.0

## Security

- 1 low-severity CVE in dev dependency (Black) - no production impact
- All security scans documented in [security report](docs/security/)

## Contributors

- Kyle Gehring (@kyle-gehring)

## What's Next (v0.2.0)

- MCP server for enhanced Claude Code integration
- Additional notification channels
- Performance optimizations
- Community-requested features

---

**Full Changelog**: https://github.com/kyle-gehring/sql-sentinel/blob/main/CHANGELOG.md
```

#### 3.6 Launch Checklist

**Pre-Launch:**
- [ ] All tests passing in CI
- [ ] PyPI package works
- [ ] Docker images work
- [ ] Documentation complete
- [ ] Demo GIF in README
- [ ] GitHub release created
- [ ] LICENSE file present
- [ ] Code of Conduct included

**Launch:**
- [ ] Tweet/LinkedIn post announcing launch
- [ ] Share in relevant communities (optional):
  - r/dataengineering
  - r/python
  - Hacker News
  - Dev.to
  - LinkedIn

**Post-Launch:**
- [ ] Monitor GitHub issues
- [ ] Respond to questions
- [ ] Fix any critical bugs
- [ ] Plan v0.2.0 features

### Day 3 Deliverables Checklist

- [ ] README enhanced with badges, demo GIF, AI-first section
- [ ] Demo GIF created and compelling
- [ ] AI workflows documentation complete
- [ ] FAQ, Architecture, Security docs created
- [ ] GitHub release v0.1.0 published
- [ ] Launch announcement posted
- [ ] All links working
- [ ] Repository looks professional

---

## Optional: Minimal MCP Server (Post Day 3)

**Scope**: Handle installation/setup ONLY (not NL‚ÜíSQL conversion)

**Purpose**: Help analysts get started without wrestling with Python environments

### MCP Server Capabilities (Minimal)

**Tool 1: Install SQL Sentinel**
```json
{
  "name": "install_sqlsentinel",
  "description": "Install SQL Sentinel and dependencies",
  "input": {
    "method": "pip|docker"
  }
}
```

**Tool 2: Initialize Project**
```json
{
  "name": "init_project",
  "description": "Create initial config files and directory structure",
  "input": {
    "project_path": "/path/to/project",
    "database_type": "postgresql|mysql|bigquery"
  }
}
```

**Tool 3: Validate Setup**
```json
{
  "name": "validate_setup",
  "description": "Check that SQL Sentinel is installed and configured correctly",
  "input": {}
}
```

### Why This Is Useful

**Problem**: Analysts get stuck on:
- Python environment setup
- Installing dependencies
- Creating initial config structure
- Database connection strings

**Solution**: MCP server handles these setup tasks, then analysts use:
- Claude Code for SQL query generation (natural language ‚Üí SQL)
- SQL Sentinel CLI for execution
- Their existing SQL skills for alert logic

### Implementation Time

**Estimate**: 4-6 hours (optional Day 4)

**Tech Stack**: Python MCP SDK

**Deliverables**:
- [ ] MCP server for setup tasks
- [ ] Installation guide
- [ ] Basic tests

---

## Success Criteria

### v0.1.0 Public Alpha Must-Haves

**Technical:**
- [x] Package name available on PyPI ‚úÖ
- [ ] `pip install sqlsentinel` works
- [ ] `docker pull sqlsentinel/sqlsentinel` works
- [ ] All tests passing in CI (92.9% coverage maintained)
- [ ] Security scans documented (acceptable risk profile)

**Documentation:**
- [ ] Professional README with demo
- [ ] Clear installation instructions
- [ ] Quick start guide (< 10 minutes)
- [ ] AI workflows documented
- [ ] Contributing guidelines

**Repository:**
- [ ] GitHub repository public
- [ ] CI/CD pipeline working
- [ ] Issue/PR templates
- [ ] License file (MIT)
- [ ] Code of Conduct

**Launch:**
- [ ] v0.1.0 release published
- [ ] Announcement posted
- [ ] Links all working

### Success Metrics (Week 1)

**Realistic Goals:**
- [ ] 5+ GitHub stars
- [ ] 10+ PyPI downloads
- [ ] 3+ Docker pulls
- [ ] 1+ quality issue/question from external user
- [ ] 0 critical bugs reported

**Stretch Goals:**
- 10+ GitHub stars
- 50+ PyPI downloads
- 1+ external contributor
- Featured on Python Weekly / Data Engineering newsletter

---

## Timeline

| Day | Morning (4h) | Afternoon (4h) | Evening (optional) |
|-----|--------------|----------------|-------------------|
| **Day 0** | Package build & install test, SQLite alert test | Docker test, examples validation, docs check | Fix any issues found |
| **Day 1** | GitHub setup, CONTRIBUTING.md, CHANGELOG.md | GitHub Actions CI/CD, pre-commit hooks | Review CI results |
| **Day 2** | Package testing, TestPyPI, PyPI publish | Docker Hub setup, multi-platform builds | Test installations |
| **Day 3** | README enhancements, demo GIF, AI docs | FAQ/Architecture/Security docs, GitHub release | Launch announcements |

**Total: 26-30 hours active work over 4 days (Day 0 + 3 days)**

**Note:** Day 0 (Pre-Launch Validation) is CRITICAL - do not skip!

---

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| PyPI publishing fails | Test with TestPyPI first |
| Docker build fails | Test multi-platform locally before pushing |
| CI pipeline breaks | Set up on feature branch first |
| Package has missing dependencies | Test in fresh virtualenv |
| Demo GIF unclear | Get feedback before publishing |
| Documentation gaps | Use AI workflows doc as template |

---

## Day 4+ (Optional - MCP Server)

If time permits after successful v0.1.0 launch:

**Focus**: Minimal MCP server for installation/setup

**Deliverables**:
- [ ] Python MCP server implementation
- [ ] 3 tools: install, init, validate
- [ ] Installation guide
- [ ] Update AI workflows docs
- [ ] Test with Claude Code

**Timeline**: 4-6 hours

---

## Checklist: Ready to Start?

**Prerequisites:**
- [ ] GitHub account ready
- [ ] PyPI account created (or will create on Day 2)
- [ ] Docker Hub account created (or will create on Day 2)
- [ ] Local development environment working
- [ ] All 530 tests passing locally
- [ ] Code committed and clean working directory

**Day 1 Ready:**
- [ ] Plan reviewed and approved
- [ ] Time allocated (8 hours)
- [ ] Coffee/energy drinks stocked ‚òï

---

**Prepared by:** Claude Code
**Date:** 2025-02-05
**Status:** Ready to Execute

**Next Step:** Begin Day 1 - Create GitHub repository and CI/CD pipeline

---

## Quick Reference Commands

```bash
# Check package name availability
pip index versions sqlsentinel

# Build package locally
poetry build

# Test package in fresh venv
python -m venv /tmp/test && source /tmp/test/bin/activate
pip install dist/sqlsentinel-*.whl
sqlsentinel --version

# Publish to TestPyPI
poetry publish --repository testpypi

# Publish to PyPI
poetry publish

# Build Docker image
docker build -t sqlsentinel/sqlsentinel:latest .

# Test Docker image
docker run --rm sqlsentinel/sqlsentinel:latest sqlsentinel --version

# Create git tag
git tag -a v0.1.0 -m "Initial public alpha release"
git push origin v0.1.0
```
